# Traffic Dam Test

## 개요
유량 제어의 기능의 효과, 제어 기능을 직접 구현함으로써 현재 개인이 진행중인 개인 프로젝트에 대한 안전성을 극한으로 끌어올려, 백엔드 개발자로서의 역량을 한층 강화 시키기, 서비스의 안전성을 책임지는 전문가로서 자리잡기 위한 나름의 도전을 해보게 되었다. 

## 기술 선정 
- k6 : 현재 사용하기 가장 용이한 Node 기반의 테스트 도구를 기반으로 스크립트를 통한 간단한 구성으로 효과적인 유량 제어 테스트 도구로 선택하게 되었다. CLI 기반으로 필요한 히스토리를 쉽게 확인할 수 있다는 점에서 선정 됨. Locust 도 활용 가능하나, CLI 환경의 온프레미스 서버에서 쓰기 용이하기 위함이다. 
- NestJS 서버 : 테스트 대상이 되는 서버. Redis 와 함께 Pub/Sub 구조로 구축되어 있으며, 이를 기반으로 FastAPI 가 LLM 특화 기능을 하는 것을 보좌하고 서비스를 유지한다. 
- FastAPI 서버 : AI 전담 서버로, Polyglot 전략으로 AI 의 특화된 도구들의 활용과 자료들을 바로바로 적용하기 용이하기에 선정됨. 
- Redis : Pub/Sub 구조를 활용한 데이터 파이프라인의 핵심 중추. 향후 AI 서버를 비롯한 모든 서버의 상태를 포함 제어 역할까지 할 중심 축인 인메모리 DB

## 기술 가설 
- 본 테스트는 '파괴'가 목적이다. 현재의 온프레미스의 서버 상에서 일정 수준으로 서비스 리소스를 분배한 상태. 이 상태에서 테스트 요청을 가했을 때, 정상적인 다중 접속, 비정상적인 어뷰징 접속 등을 검토하여 현 온프레미스 서버에서의 성능과 리소스의 특성을 파악하고, 향후 서버의 확장 혹은 리소스 추가를 위한 기반으로 삼음.
- 주요 가설 : 
    1. NestJS 게이트웨이, Redis 는 각가 512MB 로 배치 시켰으며, 이러한 최소 단위를 설정한 것은 스케일 아웃을 통한 확장 시를 감안한 각 인스턴스의 최소 수준을 의미한다. 
    2. AI 서버는 오로지 LLM 의 처리, RAG 처리 등 AI 특화 기능으로, 게이트웨이와는 완전히 별도로 독립되며, 실제로 유저의 state 를 완전히 생각하지 않으며 오로지 Redis 의 뒷편의 생산자 역할을 수행한다. 고로 물리적 데미지를 입을 가능성은 낮은 편이다. (향후 독립된 인스턴스로 만들면 더욱 명확하게 독립적이게 된다.)
        - 그러나 이때, AI 서버는 LLM 과 통신 과정에서 어느 정도 수준의 생산 소요 시간이 필요하고, 이 지점에서 NestJS 게이트웨이 서버와의 간극이 발생하고, 핸들링이 필요해진다고 판단된다. 
    3. 이러한 전제 하에 유입량의 Before Test 는 NestJS 서버에서의 큐, 요청 대기열 등 아무런 준비가 안된 상태에선 NestJS 부터 시작하여 문제가 발생 및 Redis 까지 문제가 전파될 수 있으리라 판단됨. 

## 테스트 전략 
- 타겟 : NestJS 게이트웨이 
- 목표 : 응답 불가가 발생하는 정확한 임계점(VUs) 파악하기
- 주요 부하 지점 : 
    1. Memory Leak / OOM
    2. Event Loop Blocking
    3. Redis Memory Limit : 근본적으론 OOM 이지만 구분차 포함함
- 테스트 시나리오 : AI 서버가 100 TPS 기준으로 요청 처리가 가능하다는 전제 하에 
    - SSE GET 요청 보내기 -> 연결 유지 -> POST 로 모의 질문 보내기 -> 응답 받기 -> 연결 종료 의 한 사이클을 기반으로 진행함
- 기본 시나리오 
    1. 일반 유저 시나리오 : 점진적 증가 -> 스파이크 
        1. 0명 -> 100명 (30초) : 기본 연결 테스트
        2. 100 -> 500 (1분)
        3. 500 -> 1000 (2분)
        4. 1000 -> 2000 (1분) : 예상 서버 다운 구간
        5. 2000 -> 0 (30초)
    2. 악성 유저 시나리오 : 매크로 연사
        - 구성유저 일단 5명 
        - 공격 빈도 : 0.05 초(50ms) 마다 요청 발성 -> 총 부하는 초당 100 req 수준

## 테스트 진행 필수 사항

1. 테스트 환경 설치 (debian 계열)

```shell
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

2. k6 스크립트 실행 

```shell
k6 run script.js
```

3. NestJS 서버 설정 
- `Too many open files` 에러 발생을 미연에 막고자 ubuntu 시스템의 FD 제한을 해제할 것 

```shell
ulimit -n 65535
```

4. 모니터링 준비 사항 

    1. 실시간 로그 : `docker logs -f <container_name>`
    2. 리소스 모니터링 : `docker stats`
    3. 사실 현재 쓰기 가장 좋은 것 : Grfana 대시보드 활용 가능